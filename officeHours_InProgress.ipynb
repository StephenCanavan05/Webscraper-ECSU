{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import Select\n",
    "import sys\n",
    "from selenium.webdriver.support.select import Select\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "import csv\n",
    "import re\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get user input for filename prefix\n",
    "filename_prefix = input(\"Enter your file name followed by the current semester: \")\n",
    "date_str = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs(\"webscrapedInfo\", exist_ok=True)\n",
    "os.makedirs(\"intermediateFiles\", exist_ok=True)\n",
    "os.makedirs(\"finalFiles\", exist_ok=True)\n",
    "\n",
    "# Define filenames with respective directories\n",
    "output_filename = f\"webscrapedInfo/{filename_prefix}_Output_{date_str}.csv\"\n",
    "all_faculty_info_filename = f\"webscrapedInfo/{filename_prefix}_AllFacultyInfo_{date_str}.csv\"\n",
    "exclusive_hours_filename = f\"intermediateFiles/{filename_prefix}_Exclusive_Hours_{date_str}.csv\"\n",
    "exclusive_hours_cleaned_filename = f\"intermediateFiles/{filename_prefix}_Exclusive_Hours_Cleaned_{date_str}.csv\"\n",
    "formatted_instructor_filename = f\"intermediateFiles/{filename_prefix}_Formatted_Instructor_{date_str}.csv\"\n",
    "formatted_instructor_military_filename = f\"intermediateFiles/{filename_prefix}_Formatted_Instructor_Military_{date_str}.csv\"\n",
    "formatted_instructor_further_filename = f\"intermediateFiles/{filename_prefix}_Formatted_Instructor_FurtherTimeFormat_{date_str}.csv\"\n",
    "formatted_instructor_further_updated_filename = f\"intermediateFiles/{filename_prefix}_Formatted_Instructor_FurtherTimeFormat_Updated_{date_str}.csv\"\n",
    "formatted_instructor_expanded_filename = f\"intermediateFiles/{filename_prefix}_Formatted_Instructor_FurtherTimeFormat_Expanded_{date_str}.csv\"\n",
    "formatted_instructor_expanded_lowercase_filename = f\"intermediateFiles/{filename_prefix}_Formatted_Instructor_FurtherTimeFormat_Expanded_Lowercase_{date_str}.csv\"\n",
    "formatted_instructor_expanded_lowercase_updated_filename = f\"intermediateFiles/{filename_prefix}_Formatted_Instructor_FurtherTimeFormat_Expanded_Lowercase_Updated_{date_str}.csv\"\n",
    "final_filename = f\"finalFiles/{filename_prefix}_Formatted_Instructor_FurtherTimeFormat_Expanded_Lowercase_Updated_Office_Changes_{date_str}.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Driver for firefox and loading the Eweb url\n",
    "driver = webdriver.Firefox()\n",
    "driver.implicitly_wait(10)\n",
    "\n",
    "driver.get(\"https://www.easternct.edu/faculty-directory/index.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting SearchButton\n",
    "Search = driver.find_element(by = 'id', value = 'directorySearchButton')\n",
    "Search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Locating the HTML where the info is stored\n",
    "table = driver.find_elements(by = 'class name', value = \"mix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "872\n"
     ]
    }
   ],
   "source": [
    "print(len(table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file saved as 'webscrapedInfo/6TestSpring2025_Output_2025-05-07.csv'\n"
     ]
    }
   ],
   "source": [
    "for t in table[1:]:\n",
    "    t.text\n",
    "# Assuming table is already defined\n",
    "data = [t.text.strip() for t in table[1:]]\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data, columns=[\"Extracted Text\"])\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv(output_filename, index=False)\n",
    "\n",
    "print(f\"CSV file saved as '{output_filename}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Close the webpage\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed CSV saved as 'webscrapedInfo/6TestSpring2025_AllFacultyInfo_2025-05-07.csv'\n"
     ]
    }
   ],
   "source": [
    "def parse_professor_info(text):\n",
    "    \"\"\"\n",
    "    Parse professor info from a multi-line string into a dictionary.\n",
    "    Expected format:\n",
    "      Line 1: Name\n",
    "      Line 2: Position\n",
    "      Line 3: Department\n",
    "      Subsequent lines: 'Phone:', 'Email:', 'Office:' and optionally 'Hours:'\n",
    "    \"\"\"\n",
    "    lines = [line.strip() for line in text.splitlines() if line.strip()]\n",
    "    professor = {\n",
    "        'name': None,\n",
    "        'position': None,\n",
    "        'department': None,\n",
    "        'phone': None,\n",
    "        'email': None,\n",
    "        'office': None,\n",
    "        'Hours': None\n",
    "    }\n",
    "    \n",
    "    if len(lines) >= 1:\n",
    "        professor['name'] = lines[0]\n",
    "    if len(lines) >= 2:\n",
    "        professor['position'] = lines[1]\n",
    "    if len(lines) >= 3:\n",
    "        professor['department'] = lines[2]\n",
    "    \n",
    "    for line in lines:\n",
    "        if line.startswith('Phone:'):\n",
    "            professor['phone'] = line.replace('Phone:', '').strip()\n",
    "        elif line.startswith('Email:'):\n",
    "            professor['email'] = line.replace('Email:', '').strip()\n",
    "        elif line.startswith('Office:'):\n",
    "            professor['office'] = line.replace('Office:', '').strip()\n",
    "        elif line.startswith('Hours:'):\n",
    "            professor['Hours'] = line.replace('Hours:', '').strip()\n",
    "    \n",
    "    return professor\n",
    "\n",
    "def main():\n",
    "    # Load the CSV file with extracted text\n",
    "    df = pd.read_csv(output_filename)\n",
    "    \n",
    "    # Parse each row and create a new DataFrame with structured data\n",
    "    parsed_data = df[\"Extracted Text\"].apply(parse_professor_info).tolist()\n",
    "    parsed_df = pd.DataFrame(parsed_data)\n",
    "    \n",
    "    # Save the structured DataFrame to a new CSV file\n",
    "    parsed_df.to_csv(all_faculty_info_filename, index=False)\n",
    "    print(f\"Parsed CSV saved as '{all_faculty_info_filename}'\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered data saved as 'intermediateFiles/6TestSpring2025_Exclusive_Hours_2025-05-07.csv'\n"
     ]
    }
   ],
   "source": [
    "# Filtering 'Hours' field\n",
    "df = pd.read_csv(all_faculty_info_filename)\n",
    "df_filtered = df[df['Hours'].notna() & (df['Hours'].str.strip() != '')]\n",
    "df_filtered.to_csv(exclusive_hours_filename, index=False)\n",
    "print(f\"Filtered data saved as '{exclusive_hours_filename}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered data saved as 'intermediateFiles/6TestSpring2025_Exclusive_Hours_2025-05-07.csv'\n"
     ]
    }
   ],
   "source": [
    "#Fixing Jr. name error\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(exclusive_hours_filename)\n",
    "\n",
    "# Remove 'Jr.' if it appears at the end of a name with preceding spaces\n",
    "# \\s+  -> Matches one or more spaces before \"Jr.\"\n",
    "# Jr\\. -> Matches \"Jr.\"\n",
    "# \\s*$ -> Matches any trailing spaces at the end\n",
    "df[\"name\"] = df[\"name\"].str.replace(r\"\\s+Jr\\.\\s*$\", \"\", regex=True).str.strip()\n",
    "\n",
    "# Save the modified CSV\n",
    "df.to_csv(exclusive_hours_filename, index=False)\n",
    "\n",
    "print(f\"Filtered data saved as '{exclusive_hours_filename}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated file saved as 'intermediateFiles/6TestSpring2025_Exclusive_Hours_Cleaned_2025-05-07.csv'\n"
     ]
    }
   ],
   "source": [
    "#name formatting\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(exclusive_hours_filename)\n",
    "\n",
    "# Remove 'Jr.' if it appears at the end of a name\n",
    "df[\"name\"] = df[\"name\"].str.replace(r\"\\s+Jr\\.\\s*$\", \"\", regex=True).str.strip()\n",
    "\n",
    "# Format the name as \"Last, First Initial\"\n",
    "def format_name(name):\n",
    "    name_parts = name.split()\n",
    "    if len(name_parts) >= 2:\n",
    "        last_name = name_parts[-1]  # Last name is the last word\n",
    "        first_initial = name_parts[0][0]  # First initial from first word\n",
    "        return f\"{last_name}, {first_initial}\"\n",
    "    return name  # If format is unexpected, keep the name as is\n",
    "\n",
    "df[\"name\"] = df[\"name\"].apply(format_name)\n",
    "\n",
    "# Save the cleaned CSV\n",
    "df.to_csv(exclusive_hours_cleaned_filename, index=False)\n",
    "\n",
    "print(f\"Updated file saved as '{exclusive_hours_cleaned_filename}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formatted file saved as 'intermediateFiles/6TestSpring2025_Formatted_Instructor_2025-05-07.csv'\n"
     ]
    }
   ],
   "source": [
    "#Shrinking to desired rows\n",
    "# Load the cleaned CSV\n",
    "df = pd.read_csv(exclusive_hours_cleaned_filename)\n",
    "\n",
    "# Select only the required columns\n",
    "df_filtered = df[[\"name\", \"department\", \"office\", \"Hours\"]]\n",
    "\n",
    "# Save the formatted CSV\n",
    "df_filtered.to_csv(formatted_instructor_filename, index=False)\n",
    "\n",
    "print(f\"Formatted file saved as '{formatted_instructor_filename}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated file saved as 'intermediateFiles/6TestSpring2025_Formatted_Instructor_Military_2025-05-07.csv'\n"
     ]
    }
   ],
   "source": [
    "#TimeFormatting\n",
    "# Load the CSV\n",
    "df = pd.read_csv(formatted_instructor_filename)\n",
    "\n",
    "# Function to convert time to military format\n",
    "def convert_to_military(time_str):\n",
    "    if not isinstance(time_str, str) or \"sabbatical\" in time_str.lower():\n",
    "        return time_str  # Keep non-time values unchanged\n",
    "\n",
    "    # Normalize AM/PM format (remove dots and spaces)\n",
    "    time_str = re.sub(r\"\\s*(a\\.?m\\.?|p\\.?m\\.?)\", lambda m: m.group(1).replace(\".\", \"\").upper(), time_str)\n",
    "\n",
    "    # Regular expression to match time formats like '3:00PM', '8AM-3PM', '12:00-1 PM'\n",
    "    time_pattern = re.compile(r\"(\\d{1,2}:\\d{2}|\\d{1,2})\\s*(AM|PM)?\")\n",
    "\n",
    "    def convert_match(match):\n",
    "        \"\"\"Convert matched time to 24-hour format while handling missing AM/PM properly.\"\"\"\n",
    "        time_text, am_pm = match.groups()\n",
    "        \n",
    "        # If AM/PM is missing but part of a range, infer from previous time\n",
    "        if not am_pm:\n",
    "            return time_text  # Keep as-is if AM/PM context is unclear\n",
    "\n",
    "        # Convert to 24-hour format\n",
    "        time_obj = datetime.strptime(f\"{time_text}{am_pm}\", \"%I:%M%p\" if \":\" in time_text else \"%I%p\")\n",
    "        return time_obj.strftime(\"%H:%M\")\n",
    "\n",
    "    # Replace all matched times in the string\n",
    "    time_str = time_pattern.sub(convert_match, time_str)\n",
    "\n",
    "    # Remove any leftover \"AM\" or \"PM\" that might still be in the string\n",
    "    time_str = re.sub(r\"\\s*(AM|PM)\\b\", \"\", time_str)\n",
    "\n",
    "    return time_str.strip()  # Ensure clean formatting\n",
    "\n",
    "# Apply conversion to the \"Hours\" column\n",
    "df[\"Hours\"] = df[\"Hours\"].apply(convert_to_military)\n",
    "\n",
    "# Save the updated CSV\n",
    "df.to_csv(formatted_instructor_military_filename, index=False)\n",
    "\n",
    "print(f\"Updated file saved as '{formatted_instructor_military_filename}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Updated file saved as: intermediateFiles/6TestSpring2025_Formatted_Instructor_FurtherTimeFormat_2025-05-07.csv\n"
     ]
    }
   ],
   "source": [
    "# Mapping of day name patterns to condensed formats\n",
    "# Load the CSV\n",
    "df = pd.read_csv(formatted_instructor_military_filename)\n",
    "# === Mapping of day name patterns to condensed formats ===\n",
    "day_mapping = {\n",
    "    \"M, W, F\": \"MWF\", \"M, W\": \"MW\", \"M, F\": \"MF\", \"M, Tu\": \"MT\",\n",
    "    \"Tu, Th\": \"TR\", \"M-W\": \"MW\", \"M-F\": \"MTWRF\", \"W, F\": \"WF\",\n",
    "    \"M\": \"M\", \"Tu\": \"T\", \"W\": \"W\", \"Th\": \"R\", \"F\": \"F\",\n",
    "    \"M, Tu, W\": \"MTW\", \"M, W, Th\": \"MWR\", \"Tu, W\": \"TW\",\n",
    "    \"Th, F\": \"RF\", \"M, Th\": \"MT\", \"Tu, W, Th\": \"TWR\",\n",
    "    \"M, W, F, Th\": \"MWRF\", \"M, F, Th\": \"MFT\", \"T, R, F\": \"TRF\"\n",
    "}\n",
    "\n",
    "# === Converts time to military format ===\n",
    "def format_time(time_str):\n",
    "    if time_str.strip() == \"1\":\n",
    "        return \"1300\"\n",
    "    time_str = time_str.replace(\":\", \"\")\n",
    "    if re.match(r\"^\\d{3}$\", time_str):\n",
    "        time_str = f\"0{time_str}\"\n",
    "    if time_str.isdigit():\n",
    "        time_int = int(time_str)\n",
    "        if time_int < 630:\n",
    "            time_int += 1200\n",
    "        return f\"{time_int:04d}\"\n",
    "    return time_str\n",
    "\n",
    "# === Expands 'and' in each time block ===\n",
    "def expand_and_cases(s):\n",
    "    new_parts = []\n",
    "\n",
    "    # Split multiple entries by semicolon\n",
    "    for part in s.split(\";\"):\n",
    "        part = part.strip()\n",
    "        match = re.match(r\"([A-Za-z ,]+):\\s*(.*)\", part)\n",
    "        if not match:\n",
    "            new_parts.append(part)\n",
    "            continue\n",
    "\n",
    "        days_raw, times_raw = match.groups()\n",
    "        days = [d.strip() for d in days_raw.split(\",\")]\n",
    "        time_ranges = [t.strip() for t in re.split(r\"\\band\\b\", times_raw)]\n",
    "\n",
    "        for day in days:\n",
    "            for tr in time_ranges:\n",
    "                new_parts.append(f\"{day}: {tr}\")\n",
    "\n",
    "    return \"; \".join(new_parts)\n",
    "\n",
    "# === Formats full string of hours ===\n",
    "def format_hours(hours_str):\n",
    "    if not isinstance(hours_str, str) or \"sabbatical\" in hours_str.lower():\n",
    "        return hours_str\n",
    "\n",
    "    hours_str = expand_and_cases(hours_str)\n",
    "\n",
    "    # Replace verbose day names with abbreviations\n",
    "    for full_days, short_days in day_mapping.items():\n",
    "        hours_str = re.sub(rf\"\\b{re.escape(full_days)}\\b\", short_days, hours_str)\n",
    "\n",
    "    # Extract and format time blocks\n",
    "    pattern = re.compile(r\"([MTWRF]):\\s*([\\d:]+)-([\\d:]+)\")\n",
    "    formatted_entries = []\n",
    "    for match in pattern.finditer(hours_str):\n",
    "        day, start_time, end_time = match.groups()\n",
    "        formatted_entries.append(f\"{day}, {format_time(start_time)}, {format_time(end_time)}\")\n",
    "\n",
    "    return \", \".join(formatted_entries)\n",
    "\n",
    "# === Load and process ===\n",
    "df = pd.read_csv(formatted_instructor_military_filename)\n",
    "df[\"Hours\"] = df[\"Hours\"].apply(format_hours)\n",
    "df.to_csv(formatted_instructor_further_filename, index=False)\n",
    "\n",
    "print(f\" Updated file saved as: {formatted_instructor_further_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fix names\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(formatted_instructor_further_filename)\n",
    "\n",
    "# Assuming the column with names is called 'name', adjust if necessary\n",
    "df['name'] = df['name'].str.replace(',', '').str.replace('-', '').str.replace(' ', '').str.replace(\"'\", '')\n",
    "\n",
    "# Save the updated dataframe back to a new CSV\n",
    "df.to_csv(formatted_instructor_further_updated_filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Room format\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(formatted_instructor_further_updated_filename)\n",
    "\n",
    "# Create a dictionary for the replacements\n",
    "replacement_dict = {\n",
    "    'Goddard Hall': 'goddard',\n",
    "    'Communication': 'communications',\n",
    "    'Webb Hall': 'webb',\n",
    "    'Center for Early Childhood Education': 'the_center_for_early_childhood_education',\n",
    "    'Fine Arts': 'fine_arts',\n",
    "    'Gelsi Young': 'gelsi,'\n",
    "}\n",
    "\n",
    "# Replace using the dictionary\n",
    "df['office'] = df['office'].replace(replacement_dict, regex=True)\n",
    "\n",
    "# Save the updated dataframe back to a new CSV\n",
    "df.to_csv(formatted_instructor_further_updated_filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping invalid format in row with Hours: (Spring 2025) On Sabbatical Leave- Contact Department Secretary\n",
      "Skipping invalid format in row with Hours: On Sabbatical Leave for F24/S25\n"
     ]
    }
   ],
   "source": [
    "#Splitting office hour times\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(formatted_instructor_further_updated_filename)\n",
    "\n",
    "# Function to expand hours into separate rows, splitting every third comma\n",
    "def expand_hours(row):\n",
    "    # Skip non-standard values like 'On Sabbatical Leave'\n",
    "    if isinstance(row['Hours'], str) and row['Hours'] not in ['On Sabbatical Leave', 'On Sabbatical S25']:\n",
    "        hours_list = row['Hours'].split(', ')  # Split by commas\n",
    "        new_rows = []\n",
    "\n",
    "        # Ensure we have a valid number of elements, every 3rd comma should form a new entry\n",
    "        if len(hours_list) % 3 != 0:\n",
    "            print(f\"Skipping invalid format in row with Hours: {row['Hours']}\")\n",
    "            return []  # Skip this row if the format is invalid\n",
    "\n",
    "        # Create a new row for each time slot (every 3rd element is the time slot)\n",
    "        for i in range(0, len(hours_list), 3):\n",
    "            new_row = row.copy()\n",
    "            new_row['Hours'] = f\"{hours_list[i]}, {hours_list[i+1]}, {hours_list[i+2]}\"  # Form day, time, time slot\n",
    "            new_rows.append(new_row)\n",
    "\n",
    "        return new_rows\n",
    "    else:\n",
    "        # If 'Hours' is not a valid string or contains sabbatical info, return the row as is\n",
    "        return [row]\n",
    "\n",
    "# Create a new list to hold expanded rows\n",
    "expanded_rows = []\n",
    "\n",
    "# Apply the function to each row and expand hours\n",
    "for _, row in df.iterrows():\n",
    "    expanded_rows.extend(expand_hours(row))  # Expand hours for the row\n",
    "\n",
    "# Create a new DataFrame from the expanded rows\n",
    "expanded_df = pd.DataFrame(expanded_rows)\n",
    "\n",
    "# Save the updated dataframe back to a new CSV\n",
    "expanded_df.to_csv(formatted_instructor_expanded_filename, index=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LowerCase\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(formatted_instructor_expanded_filename)\n",
    "\n",
    "# Convert all columns to lowercase using apply() with axis=0 to apply to each column\n",
    "df = df.apply(lambda col: col.str.lower() if col.dtype == \"object\" else col)\n",
    "\n",
    "# Save the updated dataframe back to a new CSV\n",
    "df.to_csv(formatted_instructor_expanded_lowercase_filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Underscore instead of spaces department and removing \" \"\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(formatted_instructor_expanded_lowercase_filename)\n",
    "\n",
    "# Replace spaces with underscores in the 'department' column\n",
    "df['department'] = df['department'].str.replace(' ', '_')\n",
    "\n",
    "# Save the updated dataframe back to a new CSV without extra quotes\n",
    "df.to_csv(formatted_instructor_expanded_lowercase_updated_filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Room Touch up removing the or in greenhouse and science\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(formatted_instructor_expanded_lowercase_updated_filename)\n",
    "\n",
    "# Define a function to handle the replacements in the 'office' column\n",
    "def adjust_office(office):\n",
    "    # Ensure \"Science\" is followed by a comma\n",
    "    if \"science\" in office.lower() and not office.lower().startswith(\"science,\"):\n",
    "        office = office.replace(\"science\", \"science,\")\n",
    "    \n",
    "    # Replace \" or \" with a comma\n",
    "    office = office.replace(\" or \", \", \")\n",
    "    \n",
    "    # Add a comma after \"greenhouse\" if not already present\n",
    "    if \"greenhouse\" in office.lower() and not office.endswith(\"greenhouse,\") and \"greenhouse\" in office:\n",
    "        office = office.replace(\"greenhouse\", \"greenhouse,\")\n",
    "    \n",
    "    return office\n",
    "\n",
    "# Apply the function to the 'office' column\n",
    "df['office'] = df['office'].apply(adjust_office)\n",
    "\n",
    "df['office'] = df['office'].str.replace(', ', '_').str.replace(' ', '_')\n",
    "df.loc[df['Hours'].str.contains('sab', case=False, na=False), 'Hours'] = 'null, null, null'\n",
    "\n",
    "df['department'] = df['department'].str.replace(',', '')\n",
    "df['department'] = df['department'] + ', '\n",
    "df['Hours'] = ' '+ df['Hours']\n",
    "df['office'] = df['office'].str.replace(\"_room\",\"\")\n",
    "\n",
    "# Save the updated dataframe back to a new CSV\n",
    "df.to_csv(final_filename, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#greenhouse\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(final_filename)\n",
    "\n",
    "# Create an empty list to store the updated rows\n",
    "updated_rows = []\n",
    "\n",
    "# Iterate over each row in the dataframe\n",
    "for _, row in df.iterrows():\n",
    "    office = row['office']\n",
    "    \n",
    "    # Check if 'greenhouse room' is in the office field\n",
    "    if 'greenhouse room' in office:\n",
    "        # Create the first row (original) - split the office at 'greenhouse room' and keep the first part\n",
    "        new_row_1 = row.copy()\n",
    "        office_parts = office.split('greenhouse room', 1)  # Split at the first occurrence of 'greenhouse room'\n",
    "        new_row_1['office'] = office_parts[0]  # Keep only the part before 'greenhouse room'\n",
    "        updated_rows.append(new_row_1)  # Add the original (modified) row\n",
    "        \n",
    "        # Create the second row (duplicate) - keep the part after 'greenhouse room'\n",
    "        new_row_2 = row.copy()\n",
    "        new_row_2['office'] = 'greenhouse room' + office_parts[1]  # Keep only the part after 'greenhouse room'\n",
    "        updated_rows.append(new_row_2)  # Add the duplicate (modified) row\n",
    "    else:\n",
    "        # If 'greenhouse room' isn't found, just add the current row\n",
    "        updated_rows.append(row)\n",
    "\n",
    "# Create a new DataFrame from the updated rows\n",
    "updated_df = pd.DataFrame(updated_rows)\n",
    "\n",
    "#replacing the slash with underscore\n",
    "updated_df['office'] = updated_df['office'].str.replace('/', '_')\n",
    "\n",
    "\n",
    "# Save the updated dataframe back to a new CSV file\n",
    "updated_df.to_csv(final_filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported to finalFiles/6TestSpring2025_Formatted_Instructor_FurtherTimeFormat_Expanded_Lowercase_Updated_Office_Changes_2025-05-07.csv\n"
     ]
    }
   ],
   "source": [
    "#Combining into one string\n",
    "# Load the final instructor course schedule CSV\n",
    "df = pd.read_csv(final_filename)\n",
    "\n",
    "df['office'] = df['office'].str.replace(r'_(?=[^_]*$)', ', ', regex=True)\n",
    "df['office'] = df['office'].str.replace(r'(\\d+)[a-zA-Z]$', r'\\1', regex=True)\n",
    "\n",
    "\n",
    "# Function to combine the columns into a single string for each row with a space after each comma\n",
    "def combine_columns(row):\n",
    "    return f\"{row['name']}, {row['department']}{row['office']},{row['Hours']}\"\n",
    "\n",
    "# Apply the function to combine the columns for each row into one formatted string\n",
    "df_combined = df.apply(combine_columns, axis=1)\n",
    "\n",
    "# Create a new DataFrame with the combined strings\n",
    "df_prolog_ready = pd.DataFrame(df_combined, columns=[\"officeHours\"])\n",
    "\n",
    "df_prolog_ready[\"officeHours\"] = df_prolog_ready[\"officeHours\"].str.replace(r'nan$', 'null, null, null', regex=True)\n",
    "\n",
    "# Sort the DataFrame alphabetically based on the first character of the 'Courses' column\n",
    "df_prolog_ready = df_prolog_ready.sort_values(by=\"officeHours\", ascending=True).reset_index(drop=True)\n",
    "\n",
    "# Export the combined and sorted DataFrame to a new CSV\n",
    "df_prolog_ready.to_csv(final_filename, index=False)\n",
    "\n",
    "print(f\"Exported to {final_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Adding in the department and formatting it : Done\n",
    "Format like prolog : done \n",
    "Convert time to military time and format it : Done\n",
    "Convert the days to the same representation : Done\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
