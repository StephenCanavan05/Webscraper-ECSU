{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WebScrapper for EWeb courses Canavan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import Select\n",
    "import sys\n",
    "from selenium.webdriver.support.select import Select\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Term select input\n",
    "x = input(\"Would you like to select the last Semester?: \")\n",
    "def selTerm():\n",
    "    if x != 'yes'|'no':\n",
    "        print('Invalid Entry, please state \"yes\" or \"no')\n",
    "        selTerm()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Driver for firefox and loading the Eweb url\n",
    "driver = webdriver.Firefox()\n",
    "driver.implicitly_wait(10)\n",
    "\n",
    "driver.get(\"https://ssb-prod.ec.easternct.edu/PROD/bwskfcls.p_termsel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select term\n",
    "elem = driver.find_elements(by = 'id', value = 'term_id')\n",
    "if x == 'yes':\n",
    "\ts = Select(elem[0])\n",
    "\ts.select_by_index(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submit term\n",
    "elem= driver.find_elements(by = 'tag name', value = 'input')\n",
    "elem[1].click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting both\n",
    "both = driver.find_element(by = 'id', value = 'oc_id')\n",
    "both.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#searching\n",
    "btn = driver.find_element(by = 'name', value = 'SUB_BTN')\n",
    "btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Locate all tables on the page\n",
    "tbl = driver.find_elements(\"tag name\", \"table\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data exported\n"
     ]
    }
   ],
   "source": [
    "#This is where all the information will be stored and appened to for .csv exporting\n",
    "info = []\n",
    "\n",
    "for tbl_index, table in enumerate(tbl[2:], start=3):  # Enumerate\n",
    "    \n",
    "    # Locate the rows in the respective table\n",
    "    rows = table.find_elements(\"tag name\", \"tr\")\n",
    "    \n",
    "    # Loop through all rows starting with the 4th row \n",
    "    for row_index, row in enumerate(rows[3:], start=4):  # Enumerate from 4th row\n",
    "        \n",
    "        # Locate all the columns in this row\n",
    "        col = row.find_elements(\"tag name\", \"td\")\n",
    "        \n",
    "        # Using the columns that hold desired data(crse,sec,day,time,room,instrcutor)\n",
    "        indices = [3,4, 5, 10, 11, 20, 21]\n",
    "        data = []\n",
    "        for col_index in indices:\n",
    "            # Avoid error if column is not present\n",
    "            if col_index < len(col):\n",
    "                data.append(col[col_index].text)\n",
    "            else:\n",
    "                data.append(\"N/A\")\n",
    "        \n",
    "        # Add the extracted data to info\n",
    "        info.append(data)\n",
    "\n",
    "# Creating of Pandas data frame\n",
    "df = pd.DataFrame(info, columns=[\"Sub\",\"Crse\", \"Sec\", \"Day\", \"Time\", \"Room\", \"Instructor\"])\n",
    "\n",
    "#Resolving blanks\n",
    "for row in range(len(df)):  # Loop through row indices\n",
    "    if df.iloc[row, 2] == ' ':  # Check if Sec has ' '\n",
    "        df.iloc[row, 0] = df.iloc[row-1, 0]  # Copy values from the previous row\n",
    "        df.iloc[row, 1] = df.iloc[row-1, 1] \n",
    "        df.iloc[row, 2] = df.iloc[row-1, 2]\n",
    "\n",
    "# Export the DataFrame to a CSV file\n",
    "df.to_csv(\"AllCourses.csv\", index=False)\n",
    "\n",
    "print(\"Data exported\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Close the webpage\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instructor schedule exported successfully.\n"
     ]
    }
   ],
   "source": [
    "# Modify instructor names by removing all instances of '(P)'\n",
    "df['Instructor'] = df['Instructor'].str.replace(r'\\(P\\)', \"\", regex=True).str.strip()\n",
    "\n",
    "\n",
    "# Filter out rows where the instructor field contains invalid names\n",
    "df = df[~df['Instructor'].isin(['TBA', '()', '',' ()', ')', '('])]\n",
    "\n",
    "# Group by instructor and concatenate all unique times into a list\n",
    "df_grouped = df.groupby('Instructor')['Time'].apply(lambda x: list(set(x))).reset_index()\n",
    "\n",
    "# Export to a new CSV file\n",
    "df_grouped.to_csv(\"InstructorSchedules.csv\", index=False)\n",
    "\n",
    "print(\"Instructor schedule exported successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instructor schedules have been cleaned and exported successfully.\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "def split_instructors(instructor_str):\n",
    "    \"\"\"\n",
    "    Splits an instructor string into individual instructor names.\n",
    "    If the string has more than one comma, we chunk them in pairs.\n",
    "    Example:\n",
    "      \"Chirico, M (), Diller, J , Doyle, M\" \n",
    "      -> [\"Chirico, M ()\", \"Diller, J\", \"Doyle, M\"]\n",
    "    \"\"\"\n",
    "    # Split by commas\n",
    "    parts = instructor_str.split(\",\")\n",
    "    # Strip whitespace\n",
    "    parts = [p.strip() for p in parts]\n",
    "    \n",
    "    # Pair them up (0/1, 2/3, 4/5, etc.)\n",
    "    # If there's an odd part out at the end, we'll just keep it as is.\n",
    "    instructors = []\n",
    "    for i in range(0, len(parts), 2):\n",
    "        if i + 1 < len(parts):\n",
    "            combined = parts[i] + \", \" + parts[i+1]\n",
    "            instructors.append(combined.strip())\n",
    "        else:\n",
    "            # If there's no matching part, just add the last piece\n",
    "            instructors.append(parts[i])\n",
    "    \n",
    "    return instructors\n",
    "\n",
    "# 1. Read your CSV file\n",
    "df = pd.read_csv(\"InstructorSchedules.csv\")\n",
    "\n",
    "# 2. Remove '(P)' from instructor names\n",
    "\n",
    "# 3. Filter out invalid instructor names\n",
    "invalid_names = ['TBA', '()', '', ' ()', ')', '(']\n",
    "df = df[~df['Instructor'].isin(invalid_names)]\n",
    "\n",
    "# 4. Parse the 'Time' column from string -> Python list\n",
    "#    (Assumes each row looks like \"['11:00 am-11:50 am', 'TBA']\" in the CSV)\n",
    "df['Time'] = df['Time'].apply(ast.literal_eval)\n",
    "\n",
    "# 5. Remove \"TBA\" from the time lists\n",
    "df['Time'] = df['Time'].apply(\n",
    "    lambda times: [t for t in times if t.strip().upper() != 'TBA']\n",
    ")\n",
    "\n",
    "# 6. Split rows that have multiple instructors\n",
    "expanded_rows = []\n",
    "for _, row in df.iterrows():\n",
    "    instructor_str = row['Instructor']\n",
    "    time_list = row['Time']\n",
    "    \n",
    "    # Split the instructor field into one or more instructors\n",
    "    instructors = split_instructors(instructor_str)\n",
    "    \n",
    "    # For each instructor, create a separate row with the same time list\n",
    "    for inst in instructors:\n",
    "        expanded_rows.append({\n",
    "            'Instructor': inst,\n",
    "            'Time': time_list\n",
    "        })\n",
    "\n",
    "# Create a new DataFrame from the expanded rows\n",
    "df_expanded = pd.DataFrame(expanded_rows)\n",
    "\n",
    "# 7. Export to a new CSV file\n",
    "df_expanded.to_csv(\"InstructorSchedules_Cleaned.csv\", index=False)\n",
    "\n",
    "print(\"Instructor schedules have been cleaned and exported successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Instructors have been grouped, times combined, and the file is saved.\n"
     ]
    }
   ],
   "source": [
    "# 1. Read the CSV file that has the Instructor and Time columns\n",
    "df = pd.read_csv(\"InstructorSchedules_Cleaned.csv\")\n",
    "\n",
    "# 2. Remove the trailing \" ()\" from Instructor names\n",
    "#    This uses a regex to remove any space + \"()\" at the end of the name.\n",
    "df['Instructor'] = df['Instructor'].str.replace(r\"\\s*\\(\\)\\s*$\", \"\", regex=True).str.strip()\n",
    "\n",
    "# 3. Convert the Time column from a string like \"['09:30 am-10:45 am']\" into a real Python list\n",
    "df['Time'] = df['Time'].apply(ast.literal_eval)\n",
    "\n",
    "# 4. Group by Instructor, then combine (concatenate) all Time lists into a single list\n",
    "#    We'll also use a set to remove duplicates, if any. \n",
    "df_grouped = (\n",
    "    df.groupby('Instructor')['Time']\n",
    "      .apply(lambda series_of_lists: sorted({t for sublist in series_of_lists for t in sublist}))\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "# 5. Sort the grouped DataFrame alphabetically by Instructor\n",
    "df_grouped = df_grouped.sort_values(by='Instructor').reset_index(drop=True)\n",
    "\n",
    "# 6. Save the final result to a new CSV file\n",
    "df_grouped.to_csv(\"InstructorGroupedTimes.csv\", index=False)\n",
    "\n",
    "print(\"Done! Instructors have been grouped, times combined, and the file is saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InstructorClassSchedulesFinal.csv has been created without TBA times.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 1. Read your CSV file (replace with your actual filename).\n",
    "df = pd.read_csv(\"InstructorGroupedTimes.csv\")\n",
    "\n",
    "# 2. Convert the 'Time' column from a string representation of a list into an actual Python list.\n",
    "#    This step is crucial because the CSV likely stores something like \"['10:00 am-10:50 am', 'TBA']\" as a string.\n",
    "df['Time'] = df['Time'].apply(ast.literal_eval)\n",
    "\n",
    "# 3. Remove 'TBA' from each list in the 'Time' column.\n",
    "df['Time'] = df['Time'].apply(\n",
    "    lambda times: [t for t in times if t.strip().upper() != 'TBA']\n",
    ")\n",
    "\n",
    "# 4. Export the cleaned-up data to a new CSV.\n",
    "df.to_csv(\"InstructorClassSchedulesFinal.csv\", index=False)\n",
    "\n",
    "print(\"InstructorClassSchedulesFinal.csv has been created without TBA times.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GITHUB, BLANKS, Downloads, GITHUB REPOSITORY\n",
    "DEVELOP WEB SCRAPER FOR OH"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
