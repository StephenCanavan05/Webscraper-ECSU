{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WebScrapper for EWeb courses Canavan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import Select\n",
    "import sys\n",
    "from selenium.webdriver.support.select import Select\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Term select input\n",
    "x = input(\"Would you like to select the last Semester?: \")\n",
    "def selTerm():\n",
    "    if x != 'yes'|'no':\n",
    "        print('Invalid Entry, please state \"yes\" or \"no')\n",
    "        selTerm()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Driver for firefox and loading the Eweb url\n",
    "driver = webdriver.Firefox()\n",
    "driver.implicitly_wait(10)\n",
    "\n",
    "driver.get(\"https://ssb-prod.ec.easternct.edu/PROD/bwskfcls.p_termsel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select term\n",
    "elem = driver.find_elements(by = 'id', value = 'term_id')\n",
    "if x == 'yes':\n",
    "\ts = Select(elem[0])\n",
    "\ts.select_by_index(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submit term\n",
    "elem= driver.find_elements(by = 'tag name', value = 'input')\n",
    "elem[1].click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting both\n",
    "both = driver.find_element(by = 'id', value = 'oc_id')\n",
    "both.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#searching\n",
    "btn = driver.find_element(by = 'name', value = 'SUB_BTN')\n",
    "btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Locate all tables on the page\n",
    "tbl = driver.find_elements(\"tag name\", \"table\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data exported\n"
     ]
    }
   ],
   "source": [
    "#This is where all the information will be stored and appened to for .csv exporting\n",
    "info = []\n",
    "\n",
    "for tbl_index, table in enumerate(tbl[2:], start=3):  # Enumerate\n",
    "    \n",
    "    # Locate the rows in the respective table\n",
    "    rows = table.find_elements(\"tag name\", \"tr\")\n",
    "    \n",
    "    # Loop through all rows starting with the 4th row \n",
    "    for row_index, row in enumerate(rows[3:], start=4):  # Enumerate from 4th row\n",
    "        \n",
    "        # Locate all the columns in this row\n",
    "        col = row.find_elements(\"tag name\", \"td\")\n",
    "        \n",
    "        # Using the columns that hold desired data(crse,sec,day,time,room,instrcutor)\n",
    "        indices = [3,4, 5, 10, 11, 20, 21]\n",
    "        data = []\n",
    "        for col_index in indices:\n",
    "            # Avoid error if column is not present\n",
    "            if col_index < len(col):\n",
    "                data.append(col[col_index].text)\n",
    "            else:\n",
    "                data.append(\"N/A\")\n",
    "        \n",
    "        # Add the extracted data to info\n",
    "        info.append(data)\n",
    "\n",
    "# Creating of Pandas data frame\n",
    "df = pd.DataFrame(info, columns=[\"Sub\",\"Crse\", \"Sec\", \"Day\", \"Time\", \"Room\", \"Instructor\"])\n",
    "\n",
    "#Resolving blanks\n",
    "for row in range(len(df)):  # Loop through row indices\n",
    "    if df.iloc[row, 2] == ' ':  # Check if Sec has ' '\n",
    "        df.iloc[row, 0] = df.iloc[row-1, 0]  # Copy values from the previous row\n",
    "        df.iloc[row, 1] = df.iloc[row-1, 1] \n",
    "        df.iloc[row, 2] = df.iloc[row-1, 2]\n",
    "\n",
    "# Export the DataFrame to a CSV file\n",
    "df.to_csv(\"AllCourses.csv\", index=False)\n",
    "\n",
    "print(\"Data exported\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Close the webpage\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instructor schedule exported successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stevo\\AppData\\Local\\Temp\\ipykernel_19764\\3974826748.py:30: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_grouped = df.groupby('Instructor').apply(group_day_times).reset_index(name='Schedule')\n"
     ]
    }
   ],
   "source": [
    "# Modify instructor names by removing all instances of '(P)'\n",
    "df['Instructor'] = df['Instructor'].str.replace(r'\\(P\\)', \"\", regex=True).str.strip()\n",
    "\n",
    "# Filter out rows where the instructor field contains invalid names\n",
    "df = df[~df['Instructor'].isin(['TBA', '()', '', ' ()', ')', '('])]\n",
    "\n",
    "# Create a new column that combines Day and Time\n",
    "# (This is optional if you prefer to work directly with the two columns.)\n",
    "df['DayTime'] = df.apply(lambda row: f\"{row['Day']}({row['Time']})\", axis=1)\n",
    "\n",
    "# Function to group times by day for each instructor\n",
    "def group_day_times(group):\n",
    "    # Create a dictionary to hold sets of times for each day\n",
    "    day_groups = {}\n",
    "    for _, row in group.iterrows():\n",
    "        day = row['Day']\n",
    "        time = row['Time']\n",
    "        # Add the time into the corresponding day group\n",
    "        day_groups.setdefault(day, set()).add(time)\n",
    "    # Format the grouped times into the desired string format\n",
    "    formatted = []\n",
    "    for day, times in day_groups.items():\n",
    "        # Join multiple times for the same day with commas\n",
    "        times_str = \", \".join(sorted(times))\n",
    "        formatted.append(f\"{day}({times_str})\")\n",
    "    # Optionally sort the formatted segments (for consistent order)\n",
    "    return \", \".join(sorted(formatted))\n",
    "\n",
    "# Group by instructor and apply the grouping function\n",
    "df_grouped = df.groupby('Instructor').apply(group_day_times).reset_index(name='Schedule')\n",
    "\n",
    "# Export the grouped instructor schedule to a CSV file\n",
    "df_grouped.to_csv(\"InstructorSchedules.csv\", index=False)\n",
    "\n",
    "print(\"Instructor schedule exported successfully.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Instructors have been grouped, times combined, and the file is saved.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1. Read the CSV file that has the Instructor and Schedule columns.\n",
    "# (Ensure this CSV contains the raw, unaltered schedule strings.)\n",
    "df = pd.read_csv(\"InstructorSchedules_Cleaned.csv\")\n",
    "\n",
    "# Remove any space + \"()\" at the end of the instructor name.\n",
    "df['Instructor'] = df['Instructor'].str.replace(r\"\\s*\\(\\)\\s*$\", \"\", regex=True).str.strip()\n",
    "\n",
    "# We no longer need to convert the Schedule column since it's already a formatted string.\n",
    "# If your CSV has a 'Time' column that is a string like:\n",
    "# \"['09:30 am-10:45 am']\", then you'd use ast.literal_eval.\n",
    "# But if the column instead contains something like:\n",
    "# \"TR(11:00 am-12:15 pm, 12:30 pm-01:45 pm)\",\n",
    "# then you should leave it as is.\n",
    "\n",
    "# For demonstration, we assume the column is named 'Schedule'\n",
    "# and contains the formatted schedule string.\n",
    "\n",
    "# Group by Instructor, combining unique schedule strings.\n",
    "# Here we simply join the unique schedule entries with a comma.\n",
    "df_grouped = (\n",
    "    df.groupby('Instructor')['Schedule']\n",
    "      .apply(lambda series: \", \".join(sorted(series.unique())))\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "# Sort the grouped DataFrame alphabetically by Instructor.\n",
    "df_grouped = df_grouped.sort_values(by='Instructor').reset_index(drop=True)\n",
    "\n",
    "# Save the final result to a new CSV file.\n",
    "df_grouped.to_csv(\"InstructorGroupedTimes.csv\", index=False)\n",
    "\n",
    "print(\"Done! Instructors have been grouped, times combined, and the file is saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Instructors have been grouped, times combined, and the file is saved.\n"
     ]
    }
   ],
   "source": [
    "# 1. Read the CSV file that has the Instructor and Schedule columns.\n",
    "df = pd.read_csv(\"InstructorGroupedTimes.csv\")\n",
    "\n",
    "# Remove any trailing space plus \"()\" from the Instructor names.\n",
    "df['Instructor'] = df['Instructor'].str.replace(r\"\\s*\\(\\)\\s*$\", \"\", regex=True).str.strip()\n",
    "\n",
    "# In this case, we assume the Schedule column already contains formatted schedule strings.\n",
    "# For grouping, we'll combine unique schedule entries.\n",
    "df_grouped = (\n",
    "    df.groupby('Instructor')['Schedule']\n",
    "      .apply(lambda schedules: \", \".join(sorted(set(schedules))))\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "# Sort the grouped DataFrame alphabetically by Instructor.\n",
    "df_grouped = df_grouped.sort_values(by='Instructor').reset_index(drop=True)\n",
    "\n",
    "# Save the final result to a new CSV file.\n",
    "df_grouped.to_csv(\"InstructorFinal.csv\", index=False)\n",
    "\n",
    "print(\"Done! Instructors have been grouped, times combined, and the file is saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InstructorSchedulesCombined.csv has been created with instructors and schedules combined.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1. Read the cleaned instructor schedule CSV file.\n",
    "df = pd.read_csv(\"InstructorClassSchedulesFinal.csv\")\n",
    "\n",
    "# 2. Convert the Schedule column (list-like strings) into a single string per row.\n",
    "df['Schedule'] = df['Schedule'].astype(str)  # Ensure all values are treated as strings\n",
    "\n",
    "# 3. Combine Instructor and Schedule into a single string per row.\n",
    "df['Combined'] = df['Instructor'] + \": \" + df['Schedule']\n",
    "\n",
    "# 4. Save the new file with just the combined column.\n",
    "df[['Combined']].to_csv(\"InstructorSchedulesCombined.csv\", index=False, header=False)\n",
    "\n",
    "print(\"InstructorSchedulesCombined.csv has been created with instructors and schedules combined.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InstructorSchedulesFinalCleaned.csv has been created with all (TBA) instances removed.\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"InstructorSchedulesCombined.csv\", header=None, names=[\"Combined\"])\n",
    "\n",
    "# 2. Remove all instances of \"(TBA)\" from the combined string.\n",
    "df[\"Combined\"] = df[\"Combined\"].str.replace(r\"\\(TBA\\)\", \"\", regex=True).str.strip()\n",
    "\n",
    "# 3. Save the cleaned file.\n",
    "df.to_csv(\"InstructorSchedulesFinalCleaned.csv\", index=False, header=False)\n",
    "\n",
    "print(\"InstructorSchedulesFinalCleaned.csv has been created with all (TBA) instances removed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GITHUB, BLANKS, Downloads, GITHUB REPOSITORY\n",
    "DEVELOP WEB SCRAPER FOR OH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2/21/25\n",
    "Think about questions you want to answer with prolog. Facts and relationships you need to create!\n",
    "ADD days to Courses!\n",
    "Format names to be one string\n",
    "Format both to have consistent format\n",
    "Hold off - Seperate Course times out(maybe)\n",
    "Format GitHub"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
