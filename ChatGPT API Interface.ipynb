{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edc36ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import csv\n",
    "import random\n",
    "from openai import OpenAI\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ef48325",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# initialize client once\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# model name for output files\n",
    "model_name = \"gpt-5\"\n",
    "\n",
    "# folders\n",
    "BQA_FOLDER = \"LogicBenchFiles/Eval .json Files/BQA\"\n",
    "MCQA_FOLDER = \"LogicBenchFiles/Eval .json Files/MCQA\"\n",
    "EASTERN_BQA_FOLDER = \"LogicBenchFiles/Eval .json Files/Eastern BQA\"\n",
    "EASTERNDATA_BQA_FOLDER = \"LogicBenchFiles/Eval .json Files/EasternData BQA\"\n",
    "\n",
    "# for consistent end prompts\n",
    "ENDPROMPT_BQA = \"Only answer 'yes' or 'no' do not provide any additional characters like punctuation or explanation just yes or no thats it.:\"\n",
    "ENDPROMPT_MCQA = \"Do not provide any additional characters like punctuation or explanation just the choice thats it (ex. Choice_1, Choice_2, Choice_3, Choice_4).:\"\n",
    "ENDPROMPT_EasternData = (\n",
    "    \"If the question is a yes or no question, only answer 'yes' or 'no'. \"\n",
    "    \"If it is a count or recall question, answer with only the exact number or the exact answer. \"\n",
    "    \"Do not include any punctuation, explanations, or extra words â€” just the direct answer.\\n\\n\"\n",
    "    \"For recall questions that require listing course sections with times and days, format exactly like this:\\n\"\n",
    "    \"Sec 1, tr, 8:00am to 9:15am, Sec 2, mwf, 8:00am to 8:50am, Sec 3, mwf, 9:00am to 9:50am\\n\"\n",
    "    \"No extra punctuation, no 'and', no trailing periods.\\n\\n\"\n",
    "    \"For recall questions that require listing names, use the professor's full name exactly as displayed in the dataset, \"\n",
    "    \"in the same order they appear. Separate names with a comma and a space, like this:\\n\"\n",
    "    \"Jane Doe, Jack H. Ryan, Beth Stevens\\n\"\n",
    "    \"Do not reorder, reformat, or add extra text of any kind.\"\n",
    ")\n",
    "\n",
    "# Dataset file paths\n",
    "DATACONPath = \"intermediateFiles/test10Spring2025_contactinfo_2025-04-02.csv\"\n",
    "DATACORPath = \"intermediateFiles/Test8Spring2025_Instructor_Course_Schedule_2025-05-07.csv\"\n",
    "DATAOHPath = \"intermediateFiles/6TestSpring2025_Exclusive_Hours_2025-05-07.csv\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2615c094",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# function to process BQA files\n",
    "def process_bqa(file_path):\n",
    "    with open(file_path, \"r\") as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    rows = []\n",
    "    for current_q in data[\"samples\"]:\n",
    "        for qa1 in current_q[\"qa_pairs\"]:\n",
    "            prompt = current_q[\"context\"] + \"\\n\" + qa1[\"question\"] + \"\\n\" + ENDPROMPT_BQA\n",
    "\n",
    "            response = client.responses.create(\n",
    "                model= model_name,\n",
    "                input=prompt,\n",
    "                store=False,\n",
    "            )\n",
    "            chat_gpt_answer = response.output_text.lower().strip()\n",
    "\n",
    "            rows.append({\n",
    "                \"Prompt\": prompt,\n",
    "                \"Context\": current_q[\"context\"],\n",
    "                \"Question\": qa1[\"question\"],\n",
    "                \"Endprompt\": ENDPROMPT_BQA,\n",
    "                \"Correct answer\": qa1[\"answer\"],\n",
    "                \"ChatGPT answer\": chat_gpt_answer\n",
    "            })\n",
    "    return rows\n",
    "\n",
    "\n",
    "# function to process MCQA files\n",
    "def process_mcqa(file_path):\n",
    "    with open(file_path, \"r\") as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    rows = []\n",
    "    for current_q in data[\"samples\"]:\n",
    "        prompt = current_q[\"context\"] + \"\\n\" + current_q[\"question\"] + \" Select the best answer from the choices below:\\n\\n\"\n",
    "        for key, value in current_q[\"choices\"].items():\n",
    "            prompt += f\"{key}: {value}\\n\"\n",
    "        prompt += \"\\n\" + ENDPROMPT_MCQA\n",
    "\n",
    "        response = client.responses.create(\n",
    "            model= model_name,\n",
    "            input=prompt,\n",
    "            store=False,\n",
    "        )\n",
    "        chat_gpt_answer = response.output_text.lower().strip()\n",
    "\n",
    "        rows.append({\n",
    "            \"Prompt\": prompt,\n",
    "            \"Context\": current_q[\"context\"],\n",
    "            \"Question\": current_q[\"question\"],\n",
    "            \"Endprompt\": ENDPROMPT_MCQA,\n",
    "            \"Correct answer\": current_q[\"answer\"],\n",
    "            \"ChatGPT answer\": chat_gpt_answer\n",
    "        })\n",
    "    return rows\n",
    "\n",
    "\n",
    "\n",
    "def write_to_csv(file_path, rows):\n",
    "    # Extract just the filename, replace extension with _completed.csv\n",
    "    base_name = os.path.basename(file_path).replace(\".json\", f\"_{model_name}_completed.csv\")\n",
    "    # Save into the same folder as the input file\n",
    "    folder = os.path.dirname(file_path)\n",
    "    csv_file = os.path.join(folder, base_name)\n",
    "\n",
    "    with open(csv_file, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=[\"Prompt\", \"Context\", \"Question\", \"Endprompt\", \"Correct answer\", \"ChatGPT answer\"])\n",
    "        writer.writeheader()\n",
    "        writer.writerows(rows)\n",
    "    print(f\"Saved: {csv_file}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6946f034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- new helper function to read dataset text ---\n",
    "def read_csv_as_text(file_path, max_lines=None):\n",
    "    \"\"\"Reads up to max_lines of CSV to include as reference text for the model.\"\"\"\n",
    "    try:\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            lines = f.readlines()\n",
    "            # keep it small enough to avoid token overload\n",
    "            preview = \"\".join(lines[:max_lines])\n",
    "            return f\"\\n\\n[DATASET PREVIEW FROM {os.path.basename(file_path)}]\\n{preview}\\n\\n\"\n",
    "    except Exception as e:\n",
    "        return f\"\\n\\n[Could not load dataset: {e}]\\n\\n\"\n",
    "\n",
    "# --- logic for dataset choice ---\n",
    "def get_dataset_and_text(context_text):\n",
    "    context_lower = context_text.lower()\n",
    "    if \"faculty office hours\" in context_lower:\n",
    "        return DATAOHPath, read_csv_as_text(DATAOHPath)\n",
    "    elif \"course times\" in context_lower:\n",
    "        return DATACORPath, read_csv_as_text(DATACORPath)\n",
    "    elif \"contact info\" in context_lower or \"faculty contact\" in context_lower:\n",
    "        return DATACONPath, read_csv_as_text(DATACONPath)\n",
    "    else:\n",
    "        return None, \"\"\n",
    "\n",
    "def process_bqaDATA(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    rows = []\n",
    "    for current_q in data[\"samples\"]:\n",
    "        time.sleep(15)\n",
    "        dataset_path, dataset_text = get_dataset_and_text(current_q[\"context\"])\n",
    "\n",
    "        for qa1 in current_q[\"qa_pairs\"]:\n",
    "            # embed dataset text directly in the prompt\n",
    "            prompt = (\n",
    "                f\"{current_q['context']}\\n{dataset_text}{qa1['question']}\\n{ENDPROMPT_EasternData}\"\n",
    "            )\n",
    "\n",
    "            displayprompt =(\n",
    "                f\"{current_q['context']}\\n{\"' Data is inserted here' \"}{qa1['question']}\\n{ENDPROMPT_EasternData}\"\n",
    "            )\n",
    "\n",
    "            response = client.responses.create(\n",
    "                model=model_name,\n",
    "                input=prompt,\n",
    "                store=False,\n",
    "            )\n",
    "\n",
    "            chat_gpt_answer = response.output_text.lower().strip()\n",
    "\n",
    "            rows.append({\n",
    "                \"Prompt\": displayprompt,\n",
    "                \"Context\": current_q[\"context\"],\n",
    "                \"Question\": qa1[\"question\"],\n",
    "                \"Dataset Used\": dataset_path if dataset_path else \"N/A\",\n",
    "                \"Endprompt\": ENDPROMPT_EasternData,\n",
    "                \"Correct answer\": qa1[\"answer\"],\n",
    "                \"ChatGPT answer\": chat_gpt_answer\n",
    "            })\n",
    "    return rows\n",
    "\n",
    "def write_to_csv(file_path, rows):\n",
    "    base_name = os.path.basename(file_path).replace(\".json\", f\"_{model_name}_completed.csv\")\n",
    "    folder = os.path.dirname(file_path)\n",
    "    csv_file = os.path.join(folder, base_name)\n",
    "\n",
    "    with open(csv_file, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        fieldnames = [\"Prompt\", \"Context\", \"Question\", \"Dataset Used\", \"Endprompt\", \"Correct answer\", \"ChatGPT answer\"]\n",
    "        writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(rows)\n",
    "    print(f\"Saved: {csv_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc4dae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# main loop for Logic Bench\n",
    "for folder, processor in [(BQA_FOLDER, process_bqa), (MCQA_FOLDER, process_mcqa)]:\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.endswith(\".json\"):\n",
    "            filepath = os.path.join(folder, filename)\n",
    "            print(f\"Processing {filepath}...\")\n",
    "            rows = processor(filepath)\n",
    "            write_to_csv(filepath, rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e327768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main loop for Eastern BQA\n",
    "for folder, processor in [(EASTERN_BQA_FOLDER, process_bqa)]:\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.endswith(\".json\"):\n",
    "            filepath = os.path.join(folder, filename)\n",
    "            print(f\"Processing {filepath}...\")\n",
    "            rows = processor(filepath)\n",
    "            write_to_csv(filepath, rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c736a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing LogicBenchFiles/Eval .json Files/EasternData BQA\\Count.json...\n",
      "Saved: LogicBenchFiles/Eval .json Files/EasternData BQA\\Count_gpt-5_completed.csv\n",
      "Processing LogicBenchFiles/Eval .json Files/EasternData BQA\\ModusPonens.json...\n",
      "Saved: LogicBenchFiles/Eval .json Files/EasternData BQA\\ModusPonens_gpt-5_completed.csv\n",
      "Processing LogicBenchFiles/Eval .json Files/EasternData BQA\\ModusTollens.json...\n",
      "Saved: LogicBenchFiles/Eval .json Files/EasternData BQA\\ModusTollens_gpt-5_completed.csv\n",
      "Processing LogicBenchFiles/Eval .json Files/EasternData BQA\\Recall.json...\n",
      "Saved: LogicBenchFiles/Eval .json Files/EasternData BQA\\Recall_gpt-5_completed.csv\n"
     ]
    }
   ],
   "source": [
    "# main loop for Eastern Dataset Questions\n",
    "for folder, processor in [(EASTERNDATA_BQA_FOLDER, process_bqaDATA)]:\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.endswith(\".json\"):\n",
    "            filepath = os.path.join(folder, filename)\n",
    "            print(f\"Processing {filepath}...\")\n",
    "            rows = processor(filepath)\n",
    "            write_to_csv(filepath, rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e749b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "import random\n",
    "import csv\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe11d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_name = \"gpt-5\"\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key= os.getenv(\"OPENAI_API_KEY\")\n",
    "    )\n",
    "\n",
    "\n",
    "response = client.responses.create(\n",
    "  model= \"gpt-4o-mini\",\n",
    "  input=\"Hello ChatGPT, What model are you?\",\n",
    "  store=True,\n",
    ")\n",
    "\n",
    "print(response.output_text);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f915f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('LogicBenchFiles/Eval .json Files/BQA/EVAL_ModusPones(BQA).json') as file :\n",
    "    questions = file.read()\n",
    "\n",
    "questions = json.loads(questions)\n",
    "questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aae3fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('LogicBenchFiles/Eval .json Files/MCQA/EVAL_ModusPones(MCQA).json') as file :\n",
    "    questions2 = file.read()\n",
    "\n",
    "questions2 = json.loads(questions2)\n",
    "questions2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432fa506",
   "metadata": {},
   "outputs": [],
   "source": [
    "q3 = questions2['samples']\n",
    "len(q3)\n",
    "print(q3[0].keys())\n",
    "\n",
    "print(q3[0]['answer'])\n",
    "print(q3[0]['choices'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7879762e",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = questions['samples']\n",
    "len(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294fdc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(q[0].keys())\n",
    "\n",
    "print(q[0]['context'])\n",
    "\n",
    "q[5]['qa_pairs']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d452d11",
   "metadata": {},
   "source": [
    "Each prompt:\n",
    "- include context ('context')\n",
    "- include question ('q_pairs')\n",
    "- compare to answer ('answer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9973960",
   "metadata": {},
   "outputs": [],
   "source": [
    "q[5]['qa_pairs'][0]['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48526767",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for current_q in q:\n",
    "        \n",
    "    for qa1 in current_q['qa_pairs']:\n",
    "        prompt = '' \n",
    "        prompt += current_q['context'] + '\\n' + qa1['question'] + '\\n' + \"Only answer 'yes' or 'no' do not provide any additonal characters like punctuation or explantation just yes or no thats it.:\"\n",
    "\n",
    "        client = OpenAI(\n",
    "        api_key= os.getenv(\"OPENAI_API_KEY\")\n",
    "        )   \n",
    "\n",
    "\n",
    "        response = client.responses.create(\n",
    "            model= \"gpt-4o-mini\",\n",
    "            input= prompt,\n",
    "            store=False,\n",
    "        )\n",
    "        chat_gpt_answer = (response.output_text);\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        print(prompt)\n",
    "        num = random.random()\n",
    "        chat_gpt = ' '\n",
    "        if num > 0.6:\n",
    "            chat_gpt = 'no'\n",
    "        elif num > 0.2:\n",
    "            chat_gpt = 'yes'\n",
    "        print('ChatGPT answer:', chat_gpt_answer.lower().strip())\n",
    "        print('answer:', qa1['answer'])\n",
    "        print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b229931d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for current_q2 in q3:\n",
    "        prompt1 = '' \n",
    "        prompt1 += current_q2['context'] + '\\n' + current_q2['question'] + ' Select the best answer from the choices below:\\n\\n' \n",
    "        \n",
    "        for key, value in current_q2['choices'].items():\n",
    "            prompt1 += f\"{key}: {value}\\n\"\n",
    "\n",
    "\n",
    "        prompt1 += \"\\nDo not provide any additonal characters like punctuation or explantation just the choice thats it(ex. Choice_1, Choice_2, Choice_3, Choice_4).:\"\n",
    "\n",
    "    \n",
    "        client = OpenAI(\n",
    "        api_key= os.getenv(\"OPENAI_API_KEY\")\n",
    "        )   \n",
    "\n",
    "\n",
    "        response = client.responses.create(\n",
    "            model= \"gpt-4o-mini\",\n",
    "            input= prompt1,\n",
    "            store=False,\n",
    "        )\n",
    "        chat_gpt_answer2 = (response.output_text);\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "        print(prompt1)\n",
    "        num = random.random()\n",
    "        chat_gpt2 = ' '\n",
    "        if num > 0.6:\n",
    "            chat_gpt2 = 'choice 1'\n",
    "        elif num > 0.2:\n",
    "            chat_gpt2 = 'choice 2'\n",
    "        print('ChatGPT answer:', chat_gpt_answer2.lower().strip())\n",
    "        print('answer:', current_q2['answer'])\n",
    "        print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
